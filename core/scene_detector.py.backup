"""
镜头检测器
功能：自动检测视频中的镜头切换点
"""

import cv2
import numpy as np
from typing import List, Dict, Optional
from scenedetect import VideoManager, SceneManager
from scenedetect.detectors import ContentDetector, ThresholdDetector, AdaptiveDetector
from utils.logger import get_logger
from .exceptions import SceneDetectionError
import config

logger = get_logger(__name__)


class SceneDetector:
    """镜头检测器"""
    
    def __init__(self, 
                 method: str = "content",
                 threshold: float = 30.0,
                 min_scene_len: float = 1.0,
                 use_gpu: bool = False):
        """
        初始化镜头检测器
        
        Args:
            method: 检测方法 (content, threshold, adaptive)
            threshold: 检测阈值
            min_scene_len: 最小镜头时长（秒）
            use_gpu: 是否使用GPU加速
        """
        self.method = method
        self.threshold = threshold
        self.min_scene_len = min_scene_len
        self.use_gpu = use_gpu
        
        logger.info(f"镜头检测器初始化: method={method}, threshold={threshold}")
    
    def detect(self, video_path: str, 
               progress_callback: Optional[callable] = None) -> List[Dict]:
        """
        检测视频中的镜头
        
        Args:
            video_path: 视频文件路径
            progress_callback: 进度回调函数
            
        Returns:
            镜头列表，每个镜头包含start_time, end_time, start_frame, end_frame
            
        Raises:
            SceneDetectionError: 检测失败时抛出
        """
        logger.info(f"开始检测镜头: {video_path}")
        
        try:
            # 创建视频管理器
            video_manager = VideoManager([video_path])
            scene_manager = SceneManager()
            
            # 选择检测器
            if self.method == "content":
                detector = ContentDetector(threshold=self.threshold)
            elif self.method == "threshold":
                detector = ThresholdDetector(threshold=self.threshold)
            elif self.method == "adaptive":
                detector = AdaptiveDetector()
            else:
                raise SceneDetectionError(f"不支持的检测方法: {self.method}")
            
            scene_manager.add_detector(detector)
            
            # 开始检测
            video_manager.start()
            
            # 获取视频信息
            fps = video_manager.get_framerate()
            total_frames = video_manager.get_duration().get_frames()
            
            # 检测场景
            scene_manager.detect_scenes(
                frame_source=video_manager,
                show_progress=True
            )
            
            # 获取场景列表
            scene_list = scene_manager.get_scene_list()
            
            # 转换为我们的格式
            scenes = []
            for i, (start_time, end_time) in enumerate(scene_list):
                start_sec = start_time.get_seconds()
                end_sec = end_time.get_seconds()
                
                # 过滤太短的镜头
                if end_sec - start_sec < self.min_scene_len:
                    continue
                
                scene = {
                    'id': f"scene_{i+1:03d}",
                    'index': i,
                    'start_time': start_sec,
                    'end_time': end_sec,
                    'duration': end_sec - start_sec,
                    'start_frame': start_time.get_frames(),
                    'end_frame': end_time.get_frames(),
                }
                scenes.append(scene)
                
                if progress_callback:
                    progress = (i + 1) / len(scene_list) * 100
                    progress_callback(progress)
            
            video_manager.release()
            
            logger.info(f"镜头检测完成: 共检测到 {len(scenes)} 个镜头")
            return scenes
            
        except Exception as e:
            logger.error(f"镜头检测失败: {str(e)}", exc_info=True)
            raise SceneDetectionError(f"镜头检测失败: {str(e)}")
    
    def detect_manual(self, video_path: str, 
                     interval: float = 5.0) -> List[Dict]:
        """
        手动按时间间隔分割镜头
        
        Args:
            video_path: 视频路径
            interval: 时间间隔（秒）
            
        Returns:
            镜头列表
        """
        logger.info(f"按 {interval} 秒间隔手动分割镜头")
        
        cap = cv2.VideoCapture(video_path)
        
        try:
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = frame_count / fps
            
            scenes = []
            current_time = 0
            index = 0
            
            while current_time < duration:
                end_time = min(current_time + interval, duration)
                
                scene = {
                    'id': f"scene_{index+1:03d}",
                    'index': index,
                    'start_time': current_time,
                    'end_time': end_time,
                    'duration': end_time - current_time,
                    'start_frame': int(current_time * fps),
                    'end_frame': int(end_time * fps),
                }
                scenes.append(scene)
                
                current_time = end_time
                index += 1
            
            logger.info(f"手动分割完成: 共 {len(scenes)} 个镜头")
            return scenes
            
        finally:
            cap.release()
    
    def refine_scenes(self, scenes: List[Dict], 
                     merge_threshold: float = 2.0) -> List[Dict]:
        """
        优化镜头列表（合并太短的镜头）
        
        Args:
            scenes: 原始镜头列表
            merge_threshold: 合并阈值（秒）
            
        Returns:
            优化后的镜头列表
        """
        if not scenes:
            return scenes
        
        refined = []
        current_scene = scenes[0].copy()
        
        for scene in scenes[1:]:
            # 如果当前镜头太短，合并到下一个
            if current_scene['duration'] < merge_threshold:
                current_scene['end_time'] = scene['end_time']
                current_scene['end_frame'] = scene['end_frame']
                current_scene['duration'] = current_scene['end_time'] - current_scene['start_time']
            else:
                refined.append(current_scene)
                current_scene = scene.copy()
        
        # 添加最后一个
        refined.append(current_scene)
        
        # 重新编号
        for i, scene in enumerate(refined):
            scene['id'] = f"scene_{i+1:03d}"
            scene['index'] = i
        
        logger.info(f"镜头优化完成: {len(scenes)} -> {len(refined)}")
        return refined
    
    def split_scene(self, scene: Dict, split_time: float) -> tuple:
        """
        在指定时间点分割镜头
        
        Args:
            scene: 要分割的镜头
            split_time: 分割时间点（秒）
            
        Returns:
            (前半部分镜头, 后半部分镜头)
        """
        if split_time <= scene['start_time'] or split_time >= scene['end_time']:
            raise ValueError("分割时间点必须在镜头时间范围内")
        
        # 计算帧数
        fps = (scene['end_frame'] - scene['start_frame']) / scene['duration']
        split_frame = int(scene['start_frame'] + (split_time - scene['start_time']) * fps)
        
        # 前半部分
        scene1 = {
            'id': f"{scene['id']}_1",
            'index': scene['index'],
            'start_time': scene['start_time'],
            'end_time': split_time,
            'duration': split_time - scene['start_time'],
            'start_frame': scene['start_frame'],
            'end_frame': split_frame,
        }
        
        # 后半部分
        scene2 = {
            'id': f"{scene['id']}_2",
            'index': scene['index'] + 1,
            'start_time': split_time,
            'end_time': scene['end_time'],
            'duration': scene['end_time'] - split_time,
            'start_frame': split_frame,
            'end_frame': scene['end_frame'],
        }
        
        return scene1, scene2
    
    def merge_scenes(self, scene1: Dict, scene2: Dict) -> Dict:
        """
        合并两个连续的镜头
        
        Args:
            scene1: 第一个镜头
            scene2: 第二个镜头
            
        Returns:
            合并后的镜头
        """
        if scene1['end_time'] != scene2['start_time']:
            raise ValueError("只能合并连续的镜头")
        
        merged = {
            'id': scene1['id'],
            'index': scene1['index'],
            'start_time': scene1['start_time'],
            'end_time': scene2['end_time'],
            'duration': scene2['end_time'] - scene1['start_time'],
            'start_frame': scene1['start_frame'],
            'end_frame': scene2['end_frame'],
        }
        
        return merged
